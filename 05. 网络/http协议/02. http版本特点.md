## Http协议

#### 11 http2.0 做了哪些改进 3.0 呢

```
http0.9: 只有get请求+html格式的字符串
http1.0: 
post+请求头的概念+非标准化的长连接（connection：keep-alive）+初步的缓存控制（expires和Last-Modified）
http1.1：默认长连接+管道机制+缓存控制（cache-control + ETag）+断点续传（Range）+虚拟网络+新的请求方法
http1.1问题：传输数据都是明文+同一TCP连接容易队头阻塞+只要请求一次的情况下还是会保持持久连接，增加服务器压力
http2.0：二进制分帧且不分先后关系 + 多路复用+ 头部压缩 + 服务器推送
```



```
http2.0缺点：丢包后整个tcp连接中所有的请求都要等待丢包重传后才能正常完成请求 + tcp和TLS建立连接的延时
http3.0：tcp换成udp + QUIC(实现可靠传输) 
```



### 0.9

只能接受GET的请求方式，服务器返回的只能是html格式的字符串

痛点：

- 请求方式唯一，返回格式唯一
- TCP 连接无法复用

### **HTTP 1.0**（简单记忆：请缓长p）

post：有了可以传输图像、视频、二进制文件的能力

请求头：请求和响应格式改变，除了请求数据，每次通信还会发送请求头（`header`）来描述一些元数据

非标准化的长连接：手动设置connection：keep-alive才会触发长连接

初步的缓存控制：只是用`header`中的 `【If-Modified-Since，Last-Modified】`和 和 `Expires` 作为缓存失效的标准





### HTTP/1.1（简单记忆：莫管缓断新虚）

特点如下：

- 默认长连接。
  - HTTP/1.1 默认开启持久连接，在 TCP 连接建立后不立即关闭，让多个 HTTP 请求得以复用。
  - 客户端和服务器都能选择随时关闭连接，则请求头中为connection:close。
  - Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间
- 管道机制。
  - 多个 HTTP 请求不用排队发送，可以批量发送，这就解决了 HTTP 队头阻塞问题。但批量发送的 HTTP 请求，必须按照发送的顺序返回响应，相当于问题解决了一半，仍然不是最佳体验。
  
  - 管道机制是将多个 HTTP 请求（request）整批提交的技术，而在发送过程中不需先等待服务器的回应。 流水线操作建立在长连接之上，可以将所有的 HTTP 请求一次性发出，而无需关心上一次发送请求的状态，虽然说客户端一次性能够发出所有的请求，但是在服务端接收到的请求还是一一进行处理的，如果当服务端返回的其中一个响应阻塞后，接下来的响应也会被阻塞。
  
    ![img](图片/16df75156f29eb46tplv-t2oaga2asx-watermark.awebp)
  
  
    
    
- 缓存控制
  - `【If-None-Match，ETag】`和` Cache-Control`
- 断点续传
  - 在 http1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，http1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
- 新的请求方式
  - PUT、DELETE、PATCH、HEAD、 OPTIONS 请求方法。
- 虚拟网络。
  - http1.1 中**新增了 host 字段**，用来指定服务器的域名。http1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。因此有了 host 字段，这样就可以将请求发往到同一台服务器上的不同网站。

HTTP/1.1 痛点：

- HTTP 队头阻塞没有彻底解决，响应端必须按照 HTTP 的发送顺序进行返回，如果排序靠前的响应特别耗时，则会阻塞排序靠后的所有响应。

#### **问题**

- 在传输数据过程中，所有内容都是明文，客户端和服务器端都无法验证对方的身份，无法保证数据的安全性。
- `HTTP/1.1` 版本默认允许复用TCP连接，但是在同一个TCP连接里，响应端必须按照 HTTP 的发送顺序进行返回，如果排序靠前的响应特别耗时，则会阻塞排序靠后的所有响应。
- `HTTP/1.x` 版本支持 `Keep-alive`，用此方案来弥补创建多次连接产生的延迟，但是同样会给服务器带来压力，并且的话，对于单文件被不断请求的服务，`Keep-alive` 会极大影响性能，因为它在文件被请求之后还保持了不必要的连接很长时间。

### **HTTP 2.0**（简单记忆：帧多推头）

- **二进制分帧**：

  >**HTTP/2 认为明文传输对机器而言太麻烦了，不方便计算机的解析，因为对于文本而言会有多义性的字符，比如回车换行到底是内容还是分隔符，在内部需要用到状态机去识别，效率比较低。于是 HTTP/2 干脆把报文全部换成二进制格式，全部传输`01`串，方便了机器的解析。**
  >
  >用**Headers帧**存放头部字段，**Data帧**存放请求体数据。分帧之后，服务器看到的不再是一个个完整的 HTTP 请求报文，而是一堆乱序的二进制帧。**这些二进制帧不存在先后关系，因此也就不会排队等待，也就没有了 HTTP 的队头阻塞问题。**

- **多路复用**：复用 `TCP` 连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，这样子解决了队头阻塞的问题。

  **一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。**

- **头部压缩**： `HTTP 1.1` 版本会出现 `「User-Agent、Cookie、Accept、Server、Range」` 等字段可能会占用几百甚至几千字节，而 `Body` 却经常只有几十字节，所以导致头部偏重。

  - 解决办法：

    首先是在服务器和客户端之间建立哈希表，将可能用到的所有字段存放在这张表中，那么在传输的时候对于之前出现过的值，只需要把**索引**(比如0，1，2，...)传给对方即可，对方拿到索引查表就行了。这种**传索引**的方式，可以说让请求头字段得到极大程度的精简和复用。

  

  ![img](图片/170ffdaa6f41c004tplv-t2oaga2asx-watermark.awebp)

  

- **服务器推送**：支持服务器未经请求，主动向客户端发送资源，即服务器推送。但是客户端可以拒收

  >HTTP2还在一定程度上改变了传统的“请求-应答”工作模式，服务器不再是完全被动地响应请求，也可以新建“流”主动向客户端发送消息。
  >
  >比如，在浏览器刚请求HTML的时候就提前把可能会用到的JS、CSS文件发给客户端，减少等待的延迟，这被称为"服务器推送"（ Server Push，也叫 Cache push）
  >
  >例如下图所示,服务端主动把JS和CSS文件推送给客户端，而不需要客户端解析HTML时再发送这些请求。
  >
  >![img](图片/16934a8dd0ad7485tplv-t2oaga2asx-watermark.awebp)
  >
  >另外需要补充的是,服务端可以主动推送，客户端也有权利选择是否接收。如果服务端推送的资源已经被浏览器缓存过，浏览器可以通过发送RST_STREAM帧来拒收。主动推送也遵守同源策略，换句话说，服务器不能随便将第三方资源推送给客户端，而必须是经过双方确认才行。
  >
  >

  

- **请求优先级**： 可以设置数据帧的优先级，让服务端先处理重要资源，优化用户体验

#### 缺点

>HTTP/2出现丢包时，整个 TCP 都要开始等待重传，那么就会阻塞该TCP连接中的所有请求（如下图）。而对于 HTTP/1.1 来说，可以开启多个 TCP 连接，出现这种情况反到只会影响其中一个连接，剩余的 TCP 连接还可以正常传输数据。
>
>![img](图片/16dd01ce6dc2315dtplv-t2oaga2asx-watermark-163323173486015.awebp)
>
>



>- TCP 以及 TCP+TLS建立连接的延时
>
>HTTP/2使用TCP协议来传输的，而如果使用HTTPS的话，还需要使用TLS协议进行安全传输，而使用TLS也需要一个握手过程，**这样就需要有两个握手延迟过程**：
>
>①在建立TCP连接的时候，需要和服务器进行三次握手来确认连接成功，也就是说需要在消耗完1.5个RTT之后才能进行数据传输。
>
>②进行TLS连接，TLS有两个版本——TLS1.2和TLS1.3，每个版本建立连接所花的时间不同，大致是需要1~2个RTT。
>
>总之，在传输数据之前，我们需要花掉 3～4 个 RTT。
>
>

### http3.0

传输协议由tcp换成udp + QUIC(实现可靠传输) 





### http1.1管道机制 vs htttp2.0 多路复用

- 图中第一种请求方式，就是单次发送request请求，收到response后再进行下一次请求，显示是很低效的。
- 于是http1.1提出了**管线化(pipelining)技术**，就是如图中第二中请求方式，**一次性发送多个request**请求。
- 然而pipelining在接收response返回时，也必须依顺序接收，如果前一个请求遇到了阻塞，后面的请求即使已经处理完毕了，仍然需要等待阻塞的请求处理完毕。这种情况就如图中第三种，第一个请求阻塞后，后面的请求都需要等待，这也就是队头阻塞(Head of line blocking)。
- 为了解决上述阻塞问题，http2中提出了多路复用(Multiplexing)技术，Multiplexing是通信和计算机网络领域的专业名词。http2中**将多个请求复用同一个tcp链接中**，将一个TCP连接分为若干个流（Stream），每个流中可以传输若干消息（Message），每个消息由若干最小的二进制帧（Frame）组成。也就是将每个request-response拆分为了细小的二进制帧Frame，这样即使一个请求被阻塞了，也不会影响其他请求，如图中第四种情况所示。









### **HTTP2.0的多路复用和HTTP1.X中的长连接复用有什么区别？**

- HTTP/1.* 一次请求-响应，建立一个连接，用完关闭；每一个请求都要建立一个连接
- HTTP/1.1 Pipeling解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，因为传输格式是文本的，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞
- HTTP/2多个请求可同时在一个连接上并行执行（由于支持二进制的格式，可以无序）某个请求任务耗时严重，不会影响到其它连接的正常执行



### 管道机制和长连接的关系

HTTP/1.1允许在持久连接上可选地使用请求管道。这是相对于keep-alive连接的又一性能优化。

即管道机制是基于长连接上的又一个可优化项



### 
